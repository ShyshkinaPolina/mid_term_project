# mid_term_project
##  Опис задачі

Мета — порівняти якість роботи різних моделей машинного навчання для класифікаційної задачі. Було відібрано 4 типи моделей, які належать до різних підходів:

- Logistic Regression
- k-Nearest Neighbors
- Decision Tree
- Gradient Boosting

## Що було зроблено

- Проведено підготовку даних (масштабування, розбиття на train/test)
- Налаштовано гіперпараметри для кожної моделі
- Обчислено F1 score та AUROC для train/test наборів
- Результати занесено у зведену таблицю
- Написано висновки на основі метрик

## Використані моделі

| Назва моделі        | Гіперпараметри                            | F1 Train | F1 Test | AUROC Train | AUROC Test |
|---------------------|--------------------------------------------|----------|---------|--------------|-------------|
| Logistic Regression | solver='liblinear'                         | 0.50     | 0.51    | 0.93         | 0.92        |
| kNN                 | n_neighbors=23                             | 0.59     | 0.58    | 0.95         | 0.93        |
| Decision Tree       | max_depth=4, random_state=42               | 0.57     | 0.56    | 0.74         | 0.73        |
| Gradient Boosting   | n_estimators=10, random_state=42, learning_rate=0.5 | 0.58     | 0.57    | 0.74         | 0.74        |

## Висновки

- **kNN** і **Logistic Regression** показали найкращий баланс якості — рекомендовано для подальшого використання.
- **Decision Tree** та **Gradient Boosting** демонструють потенціал, але потребують кращого налаштування.
- Можна дослідити інші моделі бустингу (наприклад, XGBoost, LightGBM) або використати ансамблі.

## Що можна покращити

- Виконати крос-валідацію замість одного розбиття
- Тюнінг гіперпараметрів з GridSearchCV
- Спробувати балансування класів
